{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import IndexSlice as I\n",
    "import os\n",
    "\n",
    "from crownetutils.utils.plot import PlotUtil\n",
    "from crownetutils.omnetpp.scave import CrownetSql\n",
    "from crownetutils.analysis.omnetpp import OppAnalysis\n",
    "from crownetutils.analysis.dpmm.builder import DpmmHdfBuilder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_cell_counts(map, hostId):\n",
    "    \"\"\"\n",
    "    Select the density map seen by 'hostId' for all timesteps. Only use the 'selected' \n",
    "    values calculated by the used aggregation algorithm and transfrom the map to the \n",
    "    following structure:\n",
    "\n",
    "    columns: [ simtime, cell_1, cell_2, ..., cell_n]\n",
    "    index: None (simtime is unique and used for x-axis, thus not part of the index)\n",
    "    \"\"\"\n",
    "    host_df = map[I[:, :, :, :, hostId], [\"count\", \"selection\"]]\n",
    "    host_df = host_df[host_df[\"selection\"] != 0].copy(deep=True)\n",
    "    host_df = host_df.reset_index().drop(columns=[\"source\"])\n",
    "    host_df = host_df.pivot_table(index=[\"simtime\"], columns=[\"x\", \"y\"], values=\"count\")\n",
    "    cell_idx = [f\"[{x}, {y}]\" for x, y in host_df.columns]\n",
    "    host_df.columns = host_df.columns.to_flat_index()\n",
    "    host_df.columns = pd.Index(cell_idx)\n",
    "    host_df.columns.name = None\n",
    "    host_df = host_df.reset_index()\n",
    "    return host_df\n",
    "\n",
    "def plot_cell_count(ax, host_df):\n",
    "    for i in range(1, len(host_df.columns)): # all cells without simtime column\n",
    "        ax.plot('simtime', host_df.columns[i], f\"{PlotUtil.plot_color_markers[i]}--\", data=host_df, markersize=10)\n",
    "    ax.set_title(f\"Node count in cells in local map of node\")\n",
    "    ax.set_ylabel(\"Node count\")\n",
    "    ax.set_xlabel(\"time\")\n",
    "    ax.set_xlim([2.5, 10.0])\n",
    "    ax.xaxis.set_major_formatter(plt.FormatStrFormatter('%.2f'))\n",
    "    ax.legend()\n",
    "    return ax\n",
    "\n",
    "# def get_packet_source_distribution(sql, app_path, normalize=True):\n",
    "#     \"\"\"\n",
    "#     Create square matrix of [hostId X hostId] showing the source hostId of received packets for the given application path.\n",
    "#     Example:\n",
    "#     hostId/hostId |  1  |  2  |  3  |\n",
    "#           1       |  0  |  4  |  8  |\n",
    "#           2       |  1  |  0  |  1  |\n",
    "#           3       |  6  |  6  |  0  |\n",
    "#     host_1 received 4 packets from host_2\n",
    "#     host_1 received 8 packets from host_3\n",
    "#     host_2 received 1 packet  from host_1\n",
    "#     host_2 received 1 packet  from host_3\n",
    "#     host_3 received 6 packets from host_1\n",
    "#     host_3 received 6 packets from host_2\n",
    "#     \"\"\"\n",
    "#     id_map = sql.host_ids()\n",
    "#     df = None\n",
    "#     for _id, host in id_map.items():\n",
    "#         _df = sql.vec_merge_on(f\"{id_map[_id]}{app_path}\", sql.OR([\"rcvdPkSeqNo:vector\",\"rcvdPkHostId:vector\"]))\n",
    "#         _df[\"hostId\"] = _id\n",
    "#         if df is None:\n",
    "#             df = _df \n",
    "#         else:\n",
    "#             df = pd.concat([df, _df], axis=0)\n",
    "            \n",
    "\n",
    "#     df = df.loc[:,[\"hostId\", \"rcvdPkHostId:vector\"]]\n",
    "#     df[\"rcvdPkHostId:vector\"] = pd.to_numeric(df[\"rcvdPkHostId:vector\"], downcast=\"integer\")\n",
    "#     df['val'] = 1\n",
    "#     df_rcv = df.pivot_table(index=\"hostId\", columns=[\"rcvdPkHostId:vector\"], aggfunc='count', values=[\"val\"], fill_value=0)\n",
    "#     df_rcv.columns=df_rcv.columns.droplevel()\n",
    "\n",
    "#     # normalize number of received packets (axis = 1 / over columns)\n",
    "#     if normalize:\n",
    "#         _sum = df_rcv.sum(axis=1)\n",
    "#         _sum = np.repeat(_sum.to_numpy(), _sum.shape[0]).reshape((_sum.shape[0],-1))\n",
    "#         df_rcv /= _sum\n",
    "#     return df_rcv\n",
    "\n",
    "# def plot_packet_source_distribution(ax, data, hatch_patterns=PlotUtil.hatch_patterns):\n",
    "#     patterns = itertools.cycle(hatch_patterns)\n",
    "\n",
    "#     ax = data.plot.barh(stacked=True, width=0.5, ax=ax)\n",
    "#     ax.set_title(\"Packets received from\")\n",
    "#     ax.set_xlabel(\"percentage\")\n",
    "#     bars = [i for i in ax.containers if isinstance(i, mpl.container.BarContainer)]\n",
    "#     for bar in bars:\n",
    "#         _h = next(patterns)\n",
    "#         for patch in bar:\n",
    "#             patch.set_hatch(_h)\n",
    "#     ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "#     return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_root = f\"{os.environ['HOME']}/repos/crownet/crownet/tests/omnetpp/DcDMap_localUpdate_run1/results\"\n",
    "hdf_file = \"data.h5\"\n",
    "b = DpmmHdfBuilder.get(hdf_file, data_root)\n",
    "sql = CrownetSql(vec_path=f\"{data_root}/final-#0.vec\", \n",
    "    sca_path=f\"{data_root}/final-#0.sca\", \n",
    "    network=\"TestStationaryWorld\")\n",
    "df_cell_count_1 = get_cell_counts(b.build()[\"map_p\"], hostId= 15)\n",
    "df_source_dist_1 = OppAnalysis.get_packet_source_distribution(sql, app_path=\".app[1].app\", normalize=True)\n",
    "\n",
    "\n",
    "data_root = f\"{os.environ['HOME']}/repos/crownet/crownet/tests/omnetpp/DcDMap_localUpdate_run2/results\"\n",
    "hdf_file = \"data.h5\"\n",
    "b = DpmmHdfBuilder.get(hdf_file, data_root)\n",
    "sql = CrownetSql(vec_path=f\"{data_root}/final-#0.vec\", \n",
    "    sca_path=f\"{data_root}/final-#0.sca\", \n",
    "    network=\"TestStationaryWorld\")\n",
    "df_cell_count_2 = get_cell_counts(b.build()[\"map_p\"], hostId= 15)\n",
    "df_source_dist_2 = OppAnalysis.get_packet_source_distribution(sql, app_path=\".app[1].app\", normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series node count in occupied cells (Single Node View: HostId 15)\n",
    "\n",
    "In the simulation host `15` stopped sending and receiving beacons at time\n",
    "$t_{stop} = 5s$. After $t_{TTL} = 3s$ the neighborhood table removed all beacons\n",
    "still present from other nodes. The count drops at $t=8s$ to zero for all cells\n",
    "because based on the YMF algorithm the own measurement at time of removing the\n",
    "old beacons is the newest information. With subsequently received map packets\n",
    "the density map will use the newer values as the own values get older and will\n",
    "thus be ignored by the YMF selection.\n",
    "\n",
    "The map quality is also influenced by synchronized nodes. The graphs in run 2\n",
    "show vastly different densities because the nodes start at exactly the same time\n",
    "which leads to unnaturally many collisions. In run 1 the send intervals and start\n",
    "times are changed based on the given uniform delta $U(min, max)$. Values not \n",
    "mentioned in run 2 are identical to run 1.\n",
    "\n",
    "| Parameter                | Run 1                      | Run2    |\n",
    "| ------------------------ | -------------------------- | ------- |\n",
    "| Beacon send interval     | 150 ms + U(0, 10 ms)       | 150 ms  |\n",
    "| Beacon start time        | U(0, 50 ms)                | 0 ms    |\n",
    "| Beacon TTL               | 3000 ms                    |         |\n",
    "| DPD-Map send interval    | 500 ms                     |         |\n",
    "| DPD-Map start time       | 2001 ms + U(0, 50 ms)      | 2001 ms |\n",
    "| DPD-Map merge algorithm  | Youngest measurement first |         |\n",
    "| Node 15: Stop beacon app | 5000ms                     |         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize= (20, 18))\n",
    "\n",
    "ax = plot_cell_count(axes[0][0], df_cell_count_1)\n",
    "ax.set_title(f\"Run 1: {ax.get_title()} 15\" )\n",
    "\n",
    "ax = OppAnalysis.plot_packet_source_distribution(axes[1][0], df_source_dist_1)\n",
    "ax.set_title(f\"Run 1: {ax.get_title()}\" )\n",
    "\n",
    "ax = plot_cell_count(axes[0][1], df_cell_count_2)\n",
    "ax.set_title(f\"Run 2: {ax.get_title()} 15\" )\n",
    "\n",
    "ax = OppAnalysis.plot_packet_source_distribution(axes[1][1], df_source_dist_2)\n",
    "ax.set_title(f\"Run 2: {ax.get_title()}\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crownet_edit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "cbf7d49e2d4e8675513371856e7d7c6228b3ef3a997e2c6c083f498b31985db0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
