#!/usr/bin/env python3
#
# Fingerprint-based regression test tool
#
# Accepts one or more CSV files with 6 columns: working directory,
# command to run, simulation time limit, expected fingerprint,
# expected result, tags.
# The program runs the simulations in the CSV files, and
# reports fingerprint mismatches as FAILed test cases. To facilitate
# test suite maintenance, the program also creates a new file (or files)
# with the updated fingerprints.
#
# Implementation is based on Python's unit testing library, so it can be
# integrated into larger test suites with minimal effort
#
#
# Original Authors: Andras Varga, Zoltan Bojthe
#
# Modifications for CrowNet (support for coupled simulations with sumo, vadere): Stefan Schuhbaeck
#

from __future__ import absolute_import, division, print_function, unicode_literals
import argparse
import copy
import csv
import datetime
import glob
import multiprocessing
import os
import pprint
import re
import signal
import subprocess
import sys
import threading
import time
import unittest
import logging
import signal
from enum import Enum

import yaml
from io import StringIO

from roveranalyzer.entrypoint.parser import ArgList
from roveranalyzer.simulators.controller.controllerrunner import ControlRunner
from roveranalyzer.simulators.sumo.runner import SumoRunner
from roveranalyzer.simulators.vadere.runner import VadereRunner
from roveranalyzer.simulators.opp.runner import OppRunner
from roveranalyzer.dockerrunner.dockerrunner import DockerClient, DockerCleanup, DockerReuse, stop_containers
from roveranalyzer.utils.dirdiff import csv_to_diffdict, diffdict_to_csv, create_dir_diff, compare_diff
from roveranalyzer.utils import levels, logger, set_format, set_level
import docker
from requests.exceptions import ReadTimeout


# FIXME this is a hard coded path!!! must be specified from command line or dicovered automatically
class TestGlobal:
    rootDir = os.path.abspath(".")  # the working directory in the CSV file is relative to this dir
    cpuTimeLimit = "900s"
    logFile = "test.out"
    extraArgs = ""
    debug = False
    release = False
    exitCode = 0
    FAILED = -1
    OK = 0
    executable = "/dev/null"
    container_names = []


class TestCaseType(Enum):
    SHELL = 1
    DOCKER = 2
    CROWNET = 3


class SimulationWrapper:

    def __init__(self, simulation):
        self._simulation: dict = simulation

    def store_exitcode(self, exitcode):
        self._simulation["exitcode"] = exitcode

    def store_fingerprint(self, fingerprint):
        self._simulation["computedFingerprint"] = fingerprint

    def store_diff_list(self, diff):
        self._simulation["fingerprint_diff"] = diff

    def store_vadere_error(self, err):
        self._simulation["vadere_error"] = err

    def store_control_error(self, diff):
        self._simulation["control_error"] = diff

    def get_copy(self, key, default=None):
        """
        return copy of value of given key
        """
        if default is None and key not in self._simulation:
            raise RuntimeError(f"Key '{key}' not in SimulationWrapper expected one of these:"
                               f" [{', '.join(list(self._simulation.keys()))}]")
        return copy.deepcopy(self._simulation.get(key, default))


class FingerprintTestCaseGenerator():

    def __init__(self, filterRegexList, excludeFilterRegexList, repeat, test_case_type_default):
        self.filterRegexList = filterRegexList
        self.excludeFilterRegexList = excludeFilterRegexList
        self.repeat = repeat
        self.test_case_type_default = test_case_type_default
        self.fileToSimulationsMap = {}

    def parse_test_files(self, file_list):
        testcases = []
        for file in file_list:
            simulations = self.parse_file(file)
            self.fileToSimulationsMap[file] = simulations
            testcases.extend(self.from_dict_list(simulations))
        return testcases

    def check_filter(self, title, simulation: dict):
        # if any regex matches title
        filter_res = not self.filterRegexList or ['x' for regex in self.filterRegexList if re.search(regex, title)]
        # if NO exclude-regex matches title
        exclude_res = not self.excludeFilterRegexList or \
                      not ['x' for regex in self.excludeFilterRegexList if re.search(regex, title)]
        return filter_res and exclude_res

    def create_title(self, simulation: dict):
        return f"{simulation['wd']}  {simulation['args']}  [{';'.join([f'{k}:{v}' for k, v in simulation['tags'].items()])}]"

    def from_dict_list(self, simulations):
        testcases = []
        for simulation in simulations:
            title = self.create_title(simulation)
            if self.check_filter(title, simulation):

                test_type = parse_testcase_type(simulation["tags"], self.test_case_type_default)

                if test_type == TestCaseType.DOCKER:
                    testcases.append(FingerprintContainerTestCase(title,
                                                                  SimulationWrapper(simulation),
                                                                  SimulationResultFactory(SimulationResult),
                                                                  self.repeat))
                elif test_type == TestCaseType.SHELL:
                    testcases.append(FingerprintTestCase(title,
                                                         SimulationWrapper(simulation),
                                                         SimulationResultFactory(SimulationResult),
                                                         self.repeat))
                else:
                    raise ValueError("")
        return testcases

    @staticmethod
    def comment_remover(file_content):
        p = re.compile(' *#.*$')
        for line in file_content:
            yield p.sub('', line.decode('utf-8'))

    @staticmethod
    def parse_tags(tags):
        _tags = {}
        if len(tags) > 0 and ";" not in tags:
            if ":" in tags:
                # only one container:tag pair found
                ret = tags.split(":")
                _tags[ret[0]] = ret[1]
            else:
                # assume single tag value which will be used for all containers as default
                _tags.setdefault("default", tags)
        else:
            for kv in tags.split(";"):
                if ":" in kv:
                    _kv = kv.split(":")
                    _tags[_kv[0]] = _kv[1]
        return _tags

    # parse CSV file into a list of dicts
    def parse_file(self, file_path):
        simulations = []
        f = open(file_path, 'rb')
        csvReader = csv.reader(self.comment_remover(f), delimiter=str(','), quotechar=str('"'), skipinitialspace=True)
        for fields in csvReader:
            if len(fields) == 0:
                pass  # empty line
            elif len(fields) == 6:
                if fields[4] in ['PASS', 'FAIL', 'ERROR']:

                    sim = {'file': file_path, 'line': csvReader.line_num,
                           'wd': fields[0], 'args': fields[1], 'simtimelimit': fields[2],
                           'fingerprint': fields[3], 'expectedResult': fields[4],
                           'tags': self.parse_tags(fields[5])}
                    sim["arg_list"] = ArgList.from_string(sim["args"])
                    simulations.append(sim)
                else:
                    raise Exception(file_path + " Line " + str(
                        csvReader.line_num) + ": the 5th item must contain one of 'PASS', 'FAIL', 'ERROR'" + ": " + '"' + '", "'.join(
                        fields) + '"')
            else:
                raise Exception(
                    file_path + " Line " + str(csvReader.line_num) + " must contain 6 items, but contains " + str(
                        len(fields)) + ": " + '"' + '", "'.join(fields) + '"')
        f.close()

        return simulations

    def writeUpdatedFiles(self):
        for csvFile, simulations in self.fileToSimulationsMap.items():
            updatedContents = self.formatUpdatedSimulationsTable(csvFile, simulations)
            if updatedContents:
                updatedFile = csvFile + ".UPDATED"
                ff = open(updatedFile, 'w')
                ff.write(updatedContents)
                ff.close()
                print("Check " + updatedFile + " for updated fingerprints")

    def writeFailedFiles(self):
        for csvFile, simulations in self.fileToSimulationsMap.items():
            failedContents = self.formatFailedSimulationsTable(csvFile, simulations)
            if failedContents:
                failedFile = csvFile + ".FAILED"
                ff = open(failedFile, 'w')
                ff.write(failedContents)
                ff.close()
                print("Check " + failedFile + " for failed fingerprints")

    def writeErrorFiles(self):
        for csvFile, simulations in self.fileToSimulationsMap.items():
            errorContents = self.formatErrorSimulationsTable(csvFile, simulations)
            if errorContents:
                errorFile = csvFile + ".ERROR"
                ff = open(errorFile, 'w')
                ff.write(errorContents)
                ff.close()
                print("Check " + errorFile + " for errors")

    def formatUpdatedSimulationsTable(self, csvFile, simulations):
        # if there is a computed fingerprint, print that instead of existing one
        ff = open(csvFile, 'r')
        lines = ff.readlines()
        ff.close()
        lines.insert(0, '')  # csv line count is 1..n; insert an empty item --> lines[1] is the first line

        containsComputedFingerprint = False
        for simulation in simulations:
            if 'computedFingerprint' in simulation:
                oldFingerprint = simulation['fingerprint']
                newFingerprint = simulation['computedFingerprint']
                oldFpList = oldFingerprint.split(' ')
                if '/' in newFingerprint:
                    # keep old omnetpp4 fp
                    keepFpList = [elem for elem in oldFpList if not '/' in elem]
                    if keepFpList:
                        newFingerprint = ' '.join(keepFpList) + ' ' + newFingerprint
                else:
                    # keep all old omnetpp5 fp
                    keepFpList = [elem for elem in oldFpList if '/' in elem]
                    if keepFpList:
                        newFingerprint = newFingerprint + ' ' + ' '.join(keepFpList)

                if ',' in newFingerprint:
                    newFingerprint = '"' + newFingerprint + '"'
                containsComputedFingerprint = True
                line = simulation['line']
                pattern = "\\b" + oldFingerprint + "\\b"
                (newLine, cnt) = re.subn(pattern, newFingerprint, lines[line])
                if (cnt == 1):
                    lines[line] = newLine
                else:
                    print("ERROR: Cannot replace fingerprint '%s' to '%s' at '%s' line %d:\n     %s" % (
                        oldFingerprint, newFingerprint, csvFile, line, lines[line]))
        return ''.join(lines) if containsComputedFingerprint else None

    def formatFailedSimulationsTable(self, csvFile, simulations):
        ff = open(csvFile, 'r')
        lines = ff.readlines()
        ff.close()
        lines.insert(0, '')  # csv line count is 1..n; insert an empty item --> lines[1] is the first line
        result = []

        containsFailures = False
        for simulation in simulations:
            if 'computedFingerprint' in simulation:
                oldFingerprint = simulation['fingerprint']
                newFingerprint = simulation['computedFingerprint']
                if oldFingerprint != newFingerprint:
                    if not containsFailures:
                        containsFailures = True
                        result.append("# Failures:\n")
                    result.append(lines[simulation['line']])
        return ''.join(result) if containsFailures else None

    def formatErrorSimulationsTable(self, csvFile, simulations):
        ff = open(csvFile, 'r')
        lines = ff.readlines()
        ff.close()
        lines.insert(0, '')  # csv line count is 1..n; insert an empty item --> lines[1] is the first line
        result = []

        containsErrors = False
        for simulation in simulations:
            if 'exitcode' in simulation and simulation['exitcode'] != 0:
                if not containsErrors:
                    containsErrors = True
                    result.append("# Errors:\n")
                result.append(lines[simulation['line']])

        return ''.join(result) if containsErrors else None


class FingerprintTestCaseGeneratorCrowNet(FingerprintTestCaseGenerator):

    def __init__(self, args):
        super().__init__(args.match, args.exclude, args.repeat, TestCaseType.SHELL)
        self.args = args

    # parse YAML file into list of dicts
    def parse_file(self, file_path):
        cases = []
        expected_keys = {"wd", "args", "simtimelimit", "expectedResult", "fingerprint", "tags"}
        with open(file_path, "r") as f:
            yml = yaml.load(f, Loader=yaml.BaseLoader)
        for sim_name, test in yml.items():
            # copy test data to _read_only. We will update the values in `sim`
            sim = {}
            sim["_read_only"] = test
            sim.update(**test)
            # check for missing keys
            missing_keys = expected_keys - set(sim.keys())
            if len(missing_keys) > 0:
                raise RuntimeError(f"Test file {file_path}:{sim_name} is missing keys: [{', '.join(missing_keys)}]")

            # set simulation name, file, and read fingerprints
            sim["test_name"] = sim_name
            sim["file"] = file_path
            file_name_base = re.sub("\.yml$", "", os.path.basename(sim["file"]))
            hash_base_dir = f"{os.path.dirname(os.path.abspath(file_path))}/hash.d/{file_name_base}"
            if sim["fingerprint"].startswith("file:"):
                if sim["fingerprint"] == "file:":
                    hash_path = f"{hash_base_dir}/{sim_name}.csv"
                else:
                    hash_path = sim["fingerprint"][5:-1]
                try:
                    diffs = csv_to_diffdict(hash_path)
                    sim["fingerprint"] = diffs
                except FileNotFoundError:
                    sim["fingerprint"] = {}
                    os.makedirs(hash_base_dir, exist_ok=True)
                finally:
                    sim["fingerprint_file"] = hash_path

            # --fingerprint=
            arg_list = ArgList.from_flat_list(sim["args"])

            # set omnetpp container tag - if specified
            if "omnetpp" in sim["tags"]:
                arg_list.add("--omnet-tag", sim["tags"]["omnetpp"])

            # set debug logging for test
            if (self.args.verbose > 0):
                _v = "v" * self.args.verbose
                arg_list.add_if_missing(f"-{_v}")

            # check if `args` contains executable and tags contains exec. Update `args` accordingly
            if arg_list.to_list()[0].startswith("-"):
                arg_list.add(args.executable, pos=0)

            if "exec" in sim["tags"]:
                # add runtime to arguments
                arg_list.add(sim["tags"]["exec"], pos=0)

            # set run-name if missing
            arg_list.add_if_missing("--run-name", f"{file_name_base}_{sim_name}")
            # override host-config for parallel execution of multiple containers
            arg_list.add_override(f"--override-host-config", value=None)
            # ensure write-container-log is set
            arg_list.add_override(f"--write-container-log", value=None)
            timestamp = datetime.datetime.now().isoformat().replace('-', "").replace(":", "")
            arg_list.add_override(f"--experiment-label", timestamp)

            # Crownet test can run without OMNeT++
            # todo change to parse run_script.py <subcommand> and check <sub> contains "vadere-only"
            #  * check each key to contain it "vadere-only" or "vadere-control"
            if not any([arg_list.contains_key(k) for k in ['vadere', 'vadere-control']]):
                # get OMNeT++ fingerprint hashes (if missing add dummy value)
                # FIXME Multiple Fingerprints, Alternative Values (see p.361)
                f_prints = sim["fingerprint"].setdefault("[[omnetpp]]", "ffff-ffff/tplx")
                f_prints = re.sub("\s+", "", f_prints)
                arg_list.add_override(f"--opp.fingerprint={f_prints}")
                # FIXME: Workaround due to results are saved based on config-name and experiment-label.
                # The extra directory is created based on the settings in the omnetpp.ini file
                sim["data_dir"] = f"{arg_list.get_value('--opp.-c', default='final')}_{timestamp}"
            elif arg_list.contains_key("vadere-control"):
                sim["data_dir"] = f"_{ControlRunner.OUTPUT_DEFAULT}_{timestamp}"
            else:
                sim["data_dir"] = ""

            sim["args"] = arg_list
            # check working dir and output dir and update `wd` and `output_dir` accordingly
            wd = os.path.join(args.directory, sim["wd"])
            sim["wd"] = os.path.abspath(wd)
            result_dir = os.path.join(args.output_dir, f"{sim['file']}.d", sim["test_name"])
            sim["result_dir"] = os.path.abspath(result_dir)
            # do NOT add '--result-dir' to arg_list at this point!
            # result dir is based on current repeat count and will be added to args just before execution.

            cases.append(sim)
        return cases

    def create_title(self, simulation: dict):
        return f"{simulation['wd']}  {simulation['file']}-{simulation['test_name']}"

    def from_dict_list(self, simulations):
        testcases = []
        for simulation in simulations:
            title = self.create_title(simulation)
            if self.check_filter(title, simulation):
                testcases.append(FingerprintCrowNetTestCase(title,
                                                            sim_wrapper=SimulationWrapper(simulation),
                                                            result_factory=SimulationResultFactory(
                                                                SimulationResultCrowNet),
                                                            repeat=self.repeat))

        return testcases

    def writeUpdatedFiles(self):
        for file, simulations in self.fileToSimulationsMap.items():
            for sim in simulations:
                computed_fingerprint = sim.get('computedFingerprint', None)
                if computed_fingerprint is not None:
                    updated_file = f"{sim['fingerprint_file']}.UPDATED"
                    print(updated_file)
                    diffdict_to_csv(updated_file, computed_fingerprint)

    def writeFailedFiles(self):
        for file, simulations in self.fileToSimulationsMap.items():
            for sim in simulations:
                error_list = sim.get('fingerprint_diff', None)
                if error_list is not None:
                    error_file = f"{sim['fingerprint_file']}.FAILED"
                    with open(error_file, "w", encoding="utf-8") as e:
                        for row in error_list:
                            e.write(row)
                            e.write("\n")

    def writeErrorFiles(self):
        for file, simulations in self.fileToSimulationsMap.items():
            for sim in simulations:
                vadere_error_list = sim.get('vadere_error', [])
                control_error_list = sim.get('control_error', [])
                if len(vadere_error_list) > 0 or len(control_error_list) > 0:
                    error_file = f"{sim['fingerprint_file']}.ERROR"
                    with open(error_file, "w", encoding="utf-8") as e:
                        for row in vadere_error_list:
                            e.write(row)
                            e.write("\n")
                        e.write("-" * 80)
                        e.write("\n")
                        for row in control_error_list:
                            e.write(row)
                            e.write("\n")


class SimulationResultFactory:

    def __init__(self, clb):
        self._clb = clb

    def __call__(self, *args, **kwargs):
        return self._clb(*args, **kwargs)


class SimulationResult:
    ignore_err = [
        "<!> TraCI server reported Simulation end reached.",
        "<!> Simulation time limit reached"
        ""
    ]

    def __init__(self, command, workingdir, exitcode, out, resultdir, errorMsg=None, isFingerprintOK=None,
                 computedFingerprint=None, simulatedTime=None, numEvents=None, elapsedTime=None,
                 cpuTimeLimitReached=None, **kwargs):
        self.command = command
        self.arg_list = ArgList.from_string(self.command)
        self.workingdir = workingdir
        self.exitcode = exitcode
        self.out = out
        self.resultdir = resultdir
        self.errorMsg = errorMsg
        self.isFingerprintOK = isFingerprintOK
        self.computedFingerprint = computedFingerprint
        self.simulatedTime = simulatedTime
        self.numEvents = numEvents
        self.elapsedTime = elapsedTime
        self.cpuTimeLimitReached = cpuTimeLimitReached

    def write_to_log(self, _logFile, title):
        with open(_logFile, "a") as fd:
            fd.write("------------------------------------------------------\n"
                     + "Running: " + title + "\n\n"
                     + "$ cd " + self.workingdir + "\n"
                     + "$ " + self.command + "\n\n"
                     + self.out.strip() + "\n\n"
                     + "Exit code: " + str(self.exitcode) + "\n"
                     + "Elapsed time:  " + str(round(self.elapsedTime, 2)) + "s\n\n")

        config = self.arg_list.get_value("-c")
        experiment_label = self.arg_list.get_value("--experiment-label=", default=None)
        run_log = check_sim_dir(self.resultdir, config, experiment_label)
        if run_log is not None:
            run_log = os.path.join(run_log, "test.out")
            if not os.path.exists(os.path.split(run_log)[0]):
                raise RuntimeError(
                    "Result dir not found. Did you use ${resultdir}/${configname}_${experiment} as the result base directory in the omnetpp.ini?")
            with open(run_log, "w") as fd:
                fd.write("------------------------------------------------------\n"
                         + "Running: " + title + "\n\n"
                         + "$ cd " + self.workingdir + "\n"
                         + "$ " + self.command + "\n\n"
                         + self.out.strip() + "\n\n"
                         + "Exit code: " + str(self.exitcode) + "\n"
                         + "Elapsed time:  " + str(round(self.elapsedTime, 2)) + "s\n\n")
        else:
            logging.error(f"Output directory not found for.\n  "
                          f"resultdir:{self.resultdir}\n  "
                          f"config:{config}\n  "
                          f"experiment_label:{experiment_label}")

    def parse_result(self):
        errorLines = re.findall("<!>.*", self.out, re.M)
        errorMsg = ""
        for err in errorLines:
            err = err.strip()
            if any([err.startswith(e) for e in self.ignore_err]):
                # do not track this as an error.
                m = re.search(r"at t=([0-9]*(\.[0-9]+)?)s, event #([0-9]+)", err)
                if m:
                    self.simulatedTime = float(m.group(1))
                    self.numEvents = int(m.group(3))
            elif re.search("Fingerprint", err):
                if re.search("successfully", err):
                    self.isFingerprintOK = True
                else:
                    m = re.search("(computed|calculated): ([-a-zA-Z0-9]+(/[a-zA-Z0]+)?)", err)
                    if m:
                        self.isFingerprintOK = False
                        self.computedFingerprint = m.group(2)
                    else:
                        raise Exception("Cannot parse fingerprint-related error message: " + err)
            else:
                errorMsg += "\n" + err
                if re.search("CPU time limit reached", err):
                    self.cpuTimeLimitReached = True
                m = re.search(r"at t=([0-9]*(\.[0-9]+)?)s, event #([0-9]+)", err)
                if m:
                    self.simulatedTime = float(m.group(1))
                    self.numEvents = int(m.group(3))
        self.errorMsg = errorMsg.strip()


class SimulationResultCrowNet(SimulationResult):

    def __init__(self, command, workingdir, exitcode, out, resultdir, elapsedTime, sim_wrapper):
        self.sim_wrapper = sim_wrapper
        # FIXME: omnetpp.ini creates extra directory
        self.output_path = os.path.join(resultdir, sim_wrapper.get_copy('data_dir'))
        self.opp_out_path = os.path.join(self.output_path, "container_opp.out")
        self.vadere_out_path = os.path.join(self.output_path, "container_vadere.out")
        self.control_out_path = os.path.join(self.output_path, "container_control.out")
        self.with_opp = os.path.exists(self.opp_out_path)
        self.errormsg = ""
        # write command output
        os.makedirs(self.output_path, exist_ok=True)
        with open(os.path.join(self.output_path, "command.out"), "w", encoding="utf-8") as f:
            f.write(out)

        # read OMNeT++ container output from file and use this as `out` in the super call
        if self.with_opp:
            with (open(os.path.join(self.output_path, "container_opp.out"), "r", encoding="utf-8")) as f:
                out = f.read()
        else:
            out = ""  # no OMNeT++ simulation for this test

        super().__init__(command, workingdir, exitcode, out, resultdir, elapsedTime)

    def parse_error_lines(self, path, match_pattern, ignore_pattern):
        err = []
        if not os.path.exists(path):
            return err
        match_rx = [re.compile(p) for p in match_pattern]
        ignore_rx = [re.compile(p) for p in ignore_pattern]
        with open(path, "r", encoding="utf-8") as f:
            for line in f.readlines():
                if any([re.match(p, line) for p in match_rx]) and not any([re.match(p, line) for p in ignore_rx]):
                    err.append(line)

        if len(err) > 0:
            err.insert(0, f"See: {path}")

        return err

    def write_to_log(self, _logFile, title):
        pass  # nothing to do already persisted

    def parse_result(self):
        # parse OMNeT++ results first
        expected = self.sim_wrapper.get_copy('fingerprint')
        self.crownet_computed = {}
        if self.with_opp:
            super().parse_result()
            if self.computedFingerprint is None:
                # all good OMNeT++ finger print matches
                self.crownet_computed.setdefault("[[omnetpp]]", expected['[[omnetpp]]'])
            else:
                self.crownet_computed.setdefault("[[omnetpp]]", self.computedFingerprint)

        # prase Vadere/FlowControll results
        self.crownet_computed.update(create_dir_diff(f"{self.output_path}/**", remove_front=self.output_path))
        _ok, _err = compare_diff(expected, self.crownet_computed)
        self.isFingerprintOK = _ok
        self.error_list = _err
        # control errors
        # FIXME: use container return code to determine errors
        self.control_error_list = self.parse_error_lines(
            path=self.control_out_path,
            match_pattern=[r".*Error:\s+"],
            ignore_pattern=[r".*connection closed by partner.*"]
        )
        # vadere errors
        # FIXME: use container return code to determine errors
        # TODO: parse error lines
        self.vadere_error_list = []


class SimulationTestCase(unittest.TestCase):

    def __init__(self, result_factory, sim_wrapper):
        super().__init__()
        self.result_factory = result_factory
        self.sim_wrapper = sim_wrapper

    def runSimulation(self, title, command, workingdir, resultdir):
        # run the program and log the output
        t0 = time.time()

        (exitcode, out) = self.runProgram(command, workingdir, resultdir)

        elapsedTime = time.time() - t0

        result = self.result_factory(command, workingdir, exitcode, out, resultdir,
                                     elapsedTime=elapsedTime, sim_wrapper=self.sim_wrapper)

        result.write_to_log(TestGlobal.logFile, title)
        result.parse_result()

        return result

    def runProgram(self, command, workingdir, resultdir):
        env = os.environ
        process = subprocess.Popen(['sh', '-c', command], shell=sys.platform.startswith('win'), cwd=workingdir,
                                   stdout=subprocess.PIPE, stderr=subprocess.STDOUT, env=env)
        out = process.communicate()[0]
        out = re.sub("\r", "", out.decode('utf-8'))
        return (process.returncode, out)


class FingerprintTestCase(SimulationTestCase):
    def __init__(self, title, sim_wrapper: SimulationWrapper, result_factory, repeat):
        super().__init__(result_factory, sim_wrapper)
        self.title = title
        self.csvFile = sim_wrapper.get_copy("file")
        self.wd = sim_wrapper.get_copy("wd")
        self.arg_list = sim_wrapper.get_copy("arg_list")
        self.simtimelimit = sim_wrapper.get_copy("simtimelimit")
        self.fingerprint = sim_wrapper.get_copy("fingerprint")
        self.expectedResult = sim_wrapper.get_copy("expectedResult")
        self.repeat = repeat

        self.workingdir = iif(self.wd.startswith('/'), TestGlobal.rootDir + "/" + self.wd, self.wd)
        self.wdname = f"{self.wd}_{self.arg_list.get_value('-f', '')}_{self.arg_list.get_value('-c')}_r{self.arg_list.get_value('-r', '0')}"
        self.wdname = self.wdname.replace('.', '_')
        self.wdname = self.wdname.replace('/', '_')
        self.resultdir = os.path.abspath(".") + "/results/" + self.csvFile + "/" + self.wdname

        timestamp = datetime.datetime.now().isoformat().replace('-', "").replace(":", "")
        self.arg_list.add_override(f"--experiment-label={timestamp}")

    def build_command(self):
        # Check if the command line does not contain executable name (starts with an option i.e. - char)
        # and use the executable name from the command line.
        # Otherwise, assume the first word as the name of the executable.
        self.cmdLine = self.arg_list.to_string()
        (exeName, progArgs) = (TestGlobal.executable, self.cmdLine) if (
            self.cmdLine.startswith("-")) else self.cmdLine.split(None,
                                                                  1)

        command = (
                      exeName + "_dbg" if TestGlobal.debug else exeName + "_release" if TestGlobal.release else exeName) + " -u Cmdenv " + progArgs + \
                  iif(self.simtimelimit != "", " --sim-time-limit=" + self.simtimelimit, "") + \
                  " \"--fingerprint=" + self.fingerprint + "\" --cpu-time-limit=" + TestGlobal.cpuTimeLimit + \
                  " --vector-recording=false --scalar-recording=true " + \
                  " --result-dir=" + self.resultdir + \
                  " " + TestGlobal.extraArgs
        # print("COMMAND: " + command + '\n')
        return command

    # will be called by the unittest framework! (Entry point of test)
    def runTest(self):
        # CPU time limit is a safety guard: fingerprint checks shouldn't take forever

        # run the simulation
        ensure_dir(self.resultdir)

        command = self.build_command()

        # print("COMMAND: " + command + '\n')
        anyFingerprintBad = False
        computedFingerprints = set()
        for rep in range(self.repeat):
            result = self.runSimulation(self.title, command, self.workingdir, self.resultdir)

            # process the result
            # note: fingerprint mismatch is technically NOT an error in 4.2 or before! (exitcode==0)
            self.sim_wrapper.store_exitcode(result.exitcode)
            # self.storeExitcodeCallback(result.exitcode)
            if result.exitcode != 0:
                raise Exception("runtime error with exitcode=" + str(result.exitcode) + ": " + result.errormsg)
            elif result.cpuTimeLimitReached:
                raise Exception("cpu time limit exceeded")
            elif result.simulatedTime == 0 and self.simtimelimit != '0s':
                raise Exception("zero time simulated")
            elif result.errorMsg != "":
                raise Exception("Unknown Errors or Warnings exist")
            elif result.isFingerprintOK is None:
                raise Exception("other")
            elif result.isFingerprintOK == False:
                computedFingerprints.add(result.computedFingerprint)
                anyFingerprintBad = True
            else:
                # fingerprint OK:
                computedFingerprints.add(self.fingerprint)
        #                pass

        if anyFingerprintBad:
            self.sim_wrapper.store_fingerprint(",".join(computedFingerprints))
            # self.storeFingerprintCallback(",".join(computedFingerprints))
            assert False, "some fingerprint mismatch; actual " + " '" + ",".join(computedFingerprints) + "'"

    def __str__(self):
        return self.title


class FingerprintCrowNetTestCase(SimulationTestCase):
    def __init__(self, title, sim_wrapper: SimulationWrapper, result_factory, repeat):
        super().__init__(result_factory, sim_wrapper)
        self.title = title
        self.sim_wrapper = sim_wrapper
        self.repeat = repeat
        self.expectedResult = sim_wrapper.get_copy("expectedResult")

        self.simtimelimit = sim_wrapper.get_copy("simtimelimit")
        self.workingdir = sim_wrapper.get_copy("wd")
        self.resultdir = sim_wrapper.get_copy("result_dir")

    def __str__(self):
        return self.title

    def runTest(self):

        # FIXME allow multiple runs
        if self.repeat > 1:
            print("Warning: Crownet fingerprint currently does not support multiple runs!.")
            self.repeat = 1

        some_error = False
        assert_msg = []
        for rep in range(self.repeat):
            run_result_dir = f"{self.resultdir}_r{rep}"
            cmd = self.sim_wrapper.get_copy("args")
            cmd.add_override(key="--resultdir", value=run_result_dir)
            ensure_dir(run_result_dir)
            result = self.runSimulation(self.title, cmd.to_string(), self.workingdir, run_result_dir)

            # process the result (OMNeT++ and Crownet)
            # note: fingerprint mismatch is technically NOT an error in 4.2 or before! (exitcode==0)
            self.sim_wrapper.store_exitcode(result.exitcode)
            self.sim_wrapper.store_vadere_error(result.vadere_error_list)
            self.sim_wrapper.store_control_error(result.control_error_list)
            # self.storeExitcodeCallback(result.exitcode)
            if result.exitcode != 0:
                raise Exception("runtime error with exitcode=" + str(result.exitcode) + ": " + result.errormsg)
            elif result.cpuTimeLimitReached:
                raise Exception("cpu time limit exceeded")
            elif result.simulatedTime == 0 and self.simtimelimit != '0s':
                raise Exception("zero time simulated")
            elif result.isFingerprintOK is None:
                raise Exception("other")
            elif len(result.vadere_error_list) > 0:
                raise Exception("vadere error")
            elif len(result.control_error_list) > 0:
                raise Exception("control error")
            elif result.isFingerprintOK == False:
                self.sim_wrapper.store_fingerprint(result.crownet_computed)
                self.sim_wrapper.store_diff_list(result.error_list)
                assert_msg.append("some fingerprint mismatch")
                some_error = True
            else:
                # fingerprint OK:
                pass

        # check OMNeT++ and Crownet stuff here...
        if some_error:
            assert False, ";".join(assert_msg)


class FingerprintContainerTestCase(FingerprintTestCase):
    def __init__(self, title, sim_wrapper: SimulationWrapper, result_factory, repeat):
        FingerprintTestCase.__init__(self, title, sim_wrapper, result_factory, repeat)

        # if omnetpp not present assume latest
        self.tags = sim_wrapper.get_copy("tags")
        self.tags.setdefault("omnetpp", "latest")
        self.docker_client = DockerClient.get()  # increased timeout

        if "vadere" in self.tags:
            self.mobility_runner = self.build_vadere_runner()
            self.arg_list.add_override(f"--vadere-host={self.mobility_runner.name}:9998")
        elif "sumo" in self.tags:
            self.mobility_runner = self.build_sumo_runner()
            self.arg_list.add_override(f"--sumo-host={self.mobility_runner.name}:9999")
        else:
            self.mobility_runner = None

    def get_container_base_name(self):
        """

        :return: container base name for mobility provider container. Needed for communication.
        """
        config_name = self.arg_list.get_value("-c")
        base_name = f"{self.wd.replace('/', '_')}{config_name}"
        if base_name.startswith("_"):
            base_name = base_name[1:]
        return base_name

    def build_vadere_runner(self):
        _base_name = self.get_container_base_name()
        _mobility_runner = VadereRunner(
            tag=self.tags["vadere"],
            docker_client=self.docker_client,
            name=f"vadere_{_base_name}",
            reuse_policy=DockerReuse.REMOVE_STOPPED,  # error if new container is named the same way as a running one.
            cleanup_policy=DockerCleanup.KEEP_FAILED,  # keep failed container for debug.
            detach=True,  # do not block on container start
        )
        _mobility_runner.apply_reuse_policy()
        _mobility_runner.set_working_dir(self.workingdir)
        TestGlobal.container_names.append(_mobility_runner.name)
        return _mobility_runner

    def build_sumo_runner(self):
        _base_name = self.get_container_base_name()
        _mobility_runner = SumoRunner(
            tag=self.tags["sumo"],
            docker_client=self.docker_client,
            name=f"sumo_{_base_name}",
            reuse_policy=DockerReuse.REMOVE_STOPPED,  # error if new container is named the same way as a running one.
            cleanup_policy=DockerCleanup.KEEP_FAILED,  # keep failed container for debug.
            detach=True,  # do not block on container start
        )
        _mobility_runner.apply_reuse_policy()
        _mobility_runner.set_working_dir(self.workingdir)
        TestGlobal.container_names.append(_mobility_runner.name)
        return _mobility_runner

    def build_opp_runner(self):
        _base_name = self.get_container_base_name()
        _opp_runner = OppRunner(
            tag=self.tags["omnetpp"],
            name=f"opp_{_base_name}",
            docker_client=self.docker_client,
            reuse_policy=DockerReuse.REMOVE_RUNNING,  # error if new container is named the same way as a running one.
            cleanup_policy=DockerCleanup.KEEP_FAILED,  # keep failed container for debug.
            detach=False,  # block on container start and wait for result
            run_cmd=os.path.abspath(TestGlobal.executable)  # FIXME: do not use global object
            # no fixed name, let docker choose name
        )
        _opp_runner.apply_reuse_policy()
        _opp_runner.set_working_dir(self.workingdir)
        if "NEDPATH" in _opp_runner.environment:
            del _opp_runner.environment["NEDPATH"]  # not needed. Provided by command
        TestGlobal.container_names.append(_opp_runner.name)
        return _opp_runner

    def log_path(self, resultdir):
        config = self.arg_list.get_value("-c")
        experiment_label = self.arg_list.get_value("--experiment-label=")
        logfile = os.path.join(resultdir, sim_dir(config, experiment_label), "mobilityProvider.log")
        logfile = os.path.relpath(logfile, self.mobility_runner.working_dir)
        os.makedirs(os.path.split(logfile)[0], exist_ok=True)
        return logfile

    def runProgram(self, command, workingdir, resultdir):
        opp_runner: OppRunner = self.build_opp_runner()
        ret = 64
        out = "err during starting or accessing container logs (no container logs available)"
        try:
            # start mobility provider if needed
            if self.mobility_runner is not None and "vadere" in self.tags:
                self.mobility_runner.exec_single_server(
                    logfile=self.log_path(resultdir)
                )
            elif self.mobility_runner is not None and "sumo" in self.tags:
                self.mobility_runner.single_launcher(
                    message_log=self.log_path(resultdir),
                )
            opp_ret = opp_runner.run(command, perform_cleanup=False)
            out = opp_runner.container.logs()
            out = re.sub("\r", "", out.decode('utf-8'))
            ret = opp_ret["StatusCode"]

            try:
                if self.mobility_runner is not None:
                    self.mobility_runner.container.wait(timeout=20)
            except ReadTimeout:
                logging.error(
                    f"Timeout (20s) reached while waiting for mobility_runner to finished"
                )
                ret = 255
        except RuntimeError as cErr:
            logging.error("runProgram docker runtime error:")
            logging.error(cErr)
            ret = 255
        except KeyboardInterrupt as K:
            logging.info("KeyboardInterrupt detected. Shutdown. ")
            ret = 128 + signal.SIGINT
            raise
        finally:
            # container_cleanup
            err_state = ret != 0
            logging.debug(f"cleanup with ret={ret}")
            if self.mobility_runner is not None:
                self.mobility_runner.container_cleanup(has_error_state=err_state)
            opp_runner.container_cleanup(has_error_state=err_state)

        return ret, out


class ThreadSafeIter:
    """Takes an iterator/generator and makes it thread-safe by
    serializing call to the `next` method of given iterator/generator.
    """

    def __init__(self, it):
        self.it = it
        self.lock = threading.Lock()

    def __iter__(self):
        return self

    def __next__(self):
        with self.lock:
            return next(self.it)

    next = __next__  # for python 2 compatibility


class ThreadedTestSuite(unittest.BaseTestSuite):
    """ runs toplevel tests in n threads
    """

    # How many test process at the time.
    thread_count = multiprocessing.cpu_count()

    def run(self, result):
        it = ThreadSafeIter(self.__iter__())

        result.buffered = True

        threads = []

        for i in range(self.thread_count):
            # Create self.thread_count number of threads that together will
            # cooperate removing every ip in the list. Each thread will do the
            # job as fast as it can.
            t = threading.Thread(target=self.runThread, args=(result, it))
            t.daemon = True
            t.start()
            threads.append(t)

        # Wait until all the threads are done. .join() is blocking.
        # for t in threads:
        #    t.join()
        runApp = True
        # threading.active_count() contains some IDE threads and thus never ends while called from IDE
        # while runApp and <threading.active_count()> > 1:
        while runApp and any([t.is_alive() for t in threads]):
            try:
                time.sleep(0.1)
            except KeyboardInterrupt:
                runApp = False
        return result

    def runThread(self, result, it):
        tresult = result.startThread()
        for test in it:
            if result.shouldStop:
                break
            test(tresult)
        tresult.stopThread()


class ThreadedTestResult(unittest.TestResult):
    """TestResult with threads
    """

    def __init__(self, stream=None, descriptions=None, verbosity=None):
        super(ThreadedTestResult, self).__init__()
        self.parent = None
        self.lock = threading.Lock()

    def startThread(self):
        ret = copy.copy(self)
        ret.parent = self
        return ret

    def stop(self):
        super(ThreadedTestResult, self).stop()
        if self.parent:
            self.parent.stop()

    def stopThread(self):
        if self.parent == None:
            return 0
        self.parent.testsRun += self.testsRun
        return 1

    def startTest(self, test):
        "Called when the given test is about to be run"
        super(ThreadedTestResult, self).startTest(test)
        self.oldstream = self.stream
        self.stream = StringIO()

    def stopTest(self, test):
        """Called when the given test has been run"""
        super(ThreadedTestResult, self).stopTest(test)
        out = self.stream.getvalue()
        with self.lock:
            self.stream = self.oldstream
            self.stream.write(out)


#
# Copy/paste of TextTestResult, with minor modifications in the output:
# we want to print the error text after ERROR and FAIL, but we don't want
# to print stack traces.
#
class SimulationTextTestResult(ThreadedTestResult):
    """A test result class that can print formatted text results to a stream.

    Used by TextTestRunner.
    """
    separator1 = '=' * 70
    separator2 = '-' * 70

    def __init__(self, stream, descriptions, verbosity):
        super(SimulationTextTestResult, self).__init__()
        self.stream = stream
        self.showAll = verbosity > 1
        self.dots = verbosity == 1
        self.descriptions = descriptions
        self.expectedErrors = []

    def getDescription(self, test):
        doc_first_line = test.shortDescription()
        if self.descriptions and doc_first_line:
            return '\n'.join((str(test), doc_first_line))
        else:
            return str(test)

    def startTest(self, test):
        super(SimulationTextTestResult, self).startTest(test)
        if self.showAll:
            self.stream.write("" + self.getDescription(
                test))  # NOTE: the empty "" string is needed here for python2/3 compatibility (unicode vs. str) - can be removed if only python3 is used
            self.stream.write(" ... ")
            self.stream.flush()

    def addSuccess(self, test):
        super(SimulationTextTestResult, self).addSuccess(test)
        if test.expectedResult == 'PASS':
            if self.showAll:
                self.stream.write(": PASS\n")
            elif self.dots:
                self.stream.write('.')
                self.stream.flush()
        else:
            self.addUnexpectedSuccess(test)

    def find_error_location(self, trace):
        _trace = trace
        ret = ""
        while _trace.tb_next is not None:
            if "crownet_fingerprinttest" in _trace.tb_frame.__str__():
                f = _trace.tb_frame.__str__()
                try:
                    _f = f.split(',')
                    file = _f[1].split("/")[-1]
                    line = _f[2].split()[-1]
                    ret = f"{file}:{line}"
                except:
                    ret = f
            _trace = _trace.tb_next
        return ret

    def addError(self, test, err):
        # modified
        if test.expectedResult == 'ERROR':
            self.addExpectedError(test, err)
        else:
            super(SimulationTextTestResult, self).addError(test, err)
            errmsg = f"{err[1]}: {self.find_error_location(err[2])}"
            self.errors[-1] = (
                test, errmsg)  # super class method inserts stack trace; we don't need that, so overwrite it
            if self.showAll:
                self.stream.write(": ERROR (should be %s): %s\n" % (test.expectedResult, errmsg))
            elif self.dots:
                self.stream.write('E')
                self.stream.flush()
            TestGlobal.exitCode = TestGlobal.FAILED  # result is not the expected result

    def addExpectedError(self, test, err):
        self.expectedErrors.append((test, self._exc_info_to_string(err, test)))
        self._mirrorOutput = True
        self.expectedErrors[-1] = (
            test, err[1])  # super class method inserts stack trace; we don't need that, so overwrite it
        if self.showAll:
            self.stream.write(": ERROR (expected)\n")
        elif self.dots:
            self.stream.write('e')
            self.stream.flush()

    def addFailure(self, test, err):
        # modified
        if test.expectedResult == 'FAIL':
            self.addExpectedFailure(test, err)
        else:
            super(SimulationTextTestResult, self).addFailure(test, err)
            errmsg = err[1]
            self.failures[-1] = (
                test, errmsg)  # super class method inserts stack trace; we don't need that, so overwrite it
            if self.showAll:
                self.stream.write(": FAIL (should be %s): %s\n" % (test.expectedResult, errmsg))
            elif self.dots:
                self.stream.write('F')
                self.stream.flush()
            TestGlobal.exitCode = TestGlobal.FAILED  # result is not the expected result

    def addSkip(self, test, reason):
        super(SimulationTextTestResult, self).addSkip(test, reason)
        if self.showAll:
            self.stream.write(": skipped {0!r}".format(reason))
            self.stream.write("\n")
        elif self.dots:
            self.stream.write("s")
            self.stream.flush()

    def addExpectedFailure(self, test, err):
        super(SimulationTextTestResult, self).addExpectedFailure(test, err)
        self.expectedFailures[-1] = (
            test, err[1])  # super class method inserts stack trace; we don't need that, so overwrite it
        if self.showAll:
            self.stream.write(":FAIL (expected)\n")
        elif self.dots:
            self.stream.write("x")
            self.stream.flush()

    def addUnexpectedSuccess(self, test):
        super(SimulationTextTestResult, self).addUnexpectedSuccess(test)
        self.unexpectedSuccesses[-1] = (
            test)  # super class method inserts stack trace; we don't need that, so overwrite it
        if self.showAll:
            self.stream.write(": PASS (unexpected)\n")
        elif self.dots:
            self.stream.write("u")
            self.stream.flush()
        TestGlobal.exitCode = TestGlobal.FAILED  # result is not the expected result

    def printErrors(self):
        # modified
        if self.dots or self.showAll:
            self.stream.write("\n")
        self.printErrorList('Errors', self.errors)
        self.printErrorList('Failures', self.failures)
        self.printUnexpectedSuccessList('Unexpected successes', self.unexpectedSuccesses)
        self.printErrorList('Expected errors', self.expectedErrors)
        self.printErrorList('Expected failures', self.expectedFailures)

    def printErrorList(self, flavour, errors):
        # modified
        if errors:
            self.stream.write("%s:\n" % flavour)
        for test, err in errors:
            self.stream.write("  %s (%s)\n" % (self.getDescription(test), err))

    def printUnexpectedSuccessList(self, flavour, errors):
        if errors:
            self.stream.write("%s:\n" % flavour)
        for test in errors:
            self.stream.write("  %s\n" % (self.getDescription(test)))


def sim_dir(config_name, experiment=None):
    """
    ${resultdir}/${configname}_${experiment}/....
                 ^----    sim_dir       ---^
    """
    exp = datetime.datetime.now().isoformat().replace('-', "").replace(":", "") if experiment is None else experiment
    return f"{config_name}_{exp}"


def check_sim_dir(base_dir, config_name, experiment=None):
    """
    In the omnetpp.ini file the use may define multiple ways to save resutl data.
    1) ${resultdir}/${configname}_${experiment}/....
    2) ${resultdir}/${configname}/....
    check if 1) or 2) exist and use the one found. (1) will have precedence
    """
    experiment = "" if experiment is None else experiment
    p1 = os.path.join(base_dir, f"{config_name}_{experiment}")
    p2 = os.path.join(base_dir, f"{config_name}")

    if os.path.exists(p1):
        return p1
    if os.path.exists(p2):
        return p2
    return None


def parse_testcase_type(tags: dict, default_type=TestCaseType.DOCKER):
    # default to docker based tests in the CROWNET project
    if tags is None or "type" not in tags:
        return default_type

    type_str = tags["type"]
    if type_str.upper() in TestCaseType.__members__:
        return TestCaseType[type_str.upper()]
    else:
        return default_type


def iif(cond, t, f):
    return t if cond else f


def ensure_dir(f):
    try:
        os.makedirs(f)
    except:
        pass  # do nothing if already exist


def run_testcases(cases):
    test_suite = ThreadedTestSuite()
    test_suite.addTests(cases)
    test_suite.thread_count = args.threads
    test_suite.repeat = args.repeat

    test_runner = unittest.TextTestRunner(stream=sys.stdout, verbosity=9, resultclass=SimulationTextTestResult)

    test_runner.run(test_suite)


def opp_main(args):
    if not args.testspecfiles:
        args.testspecfiles = glob.glob('*.csv')

    if args.test_case_type_default.upper() in TestCaseType.__members__:
        args.test_case_type_default = TestCaseType[args.test_case_type_default.upper()]
    else:
        args.test_case_type_default = TestCaseType.SHELL

    TestGlobal.debug = args.debug

    generator = FingerprintTestCaseGenerator(args.match, args.exclude, args.repeat, args.test_case_type_default)
    testcases = generator.parse_test_files(args.testspecfiles)

    run_testcases(testcases)

    print()
    generator.writeUpdatedFiles()
    generator.writeErrorFiles()
    generator.writeFailedFiles()
    print("Log has been saved to %s" % TestGlobal.logFile)

    # FIXME: do not use global exit code
    return TestGlobal.exitCode


def crownet_main(args):
    if not args.testspecfiles:
        args.testspecfiles = glob.glob('**/*.yml', recursive=True)

    generator = FingerprintTestCaseGeneratorCrowNet(args)
    testcases = generator.parse_test_files(args.testspecfiles)

    run_testcases(testcases)

    generator.writeUpdatedFiles()
    generator.writeErrorFiles()
    generator.writeFailedFiles()
    print("Log has been saved to %s" % TestGlobal.logFile)

    # FIXME: do not use global exit code
    return TestGlobal.exitCode


def opp_argparser(parser: argparse.ArgumentParser):
    parser.add_argument('testspecfiles', nargs='*', metavar='testspecfile',
                        help='CSV files that contain the tests to run (default: *.csv). Expected CSV file columns: '
                             'working directory, command to run, simulation time limit, expected fingerprint, expected'
                             ' result, tags. '
                             'The command column may contain only options without a program name (i.e. it starts with - ). '
                             'In this case the --executable option can be used to specify a program name.'
                             'use following tags to specify test case type. type:shell or type:docker. If not type '
                             'tag is '
                             'set the default behaviour is configured with --test-case-type'
                        )
    parser.add_argument('-d', '--debug', action='store_true',
                        help='Run debug executables: use the debug version of the executable (appends _dbg to the '
                             'executable name)')
    parser.add_argument('-s', '--release', action='store_true',
                        help='Run release executables: use the release version of the executable (appends _release to '
                             'the executable name)')
    parser.add_argument('-a', '--oppargs', action='append', metavar="extra_args", dest='extra_args',
                        nargs=argparse.REMAINDER,
                        help='extra opp_run arguments until the end of the line')
    parser.add_argument('-m', '--match', action='append', metavar='regex',
                        help='Line filter: a line (more precisely, workingdir+SPACE+args) must match any of the regular'
                             ' expressions in order for that test case to be run')
    parser.add_argument('-x', '--exclude', action='append', metavar='regex',
                        help='Negative line filter: a line (more precisely, workingdir+SPACE+args) must NOT match any '
                             'of the regular expressions in order for that test case to be run')
    parser.add_argument('-e', '--executable',
                        default="opp_run",
                        help='Determines which binary to execute (e.g. opp_run_dbg, opp_run_release) if the command '
                             'column in the CSV file does not specify one.')
    parser.add_argument('--log-file',
                        required=False,
                        dest="log_file",
                        default="opp_test.out",
                        help="output file for all tests")
    parser.add_argument('--test-case-type',
                        dest="test_case_type_default",
                        default="shell",
                        required=False,
                        help="specify test case type as 'shell' or 'docker' ")

    parser.set_defaults(main_func=opp_main)
    return parser


def crownet_argparser(parser: argparse.ArgumentParser):
    parser.add_argument('testspecfiles', nargs='*', metavar='testspecfile',
                        help='Test files that contain the tests to run (default: **/*.yml)'
                        )
    parser.add_argument('-e', '--executable',
                        default="run_script.py",
                        help='Determines which binary to execute if the command '
                             'column in the test file does not specify one.')
    parser.add_argument('-a', '--crownetargs', action='append', metavar="extraargs", dest='extra_args',
                        nargs=argparse.REMAINDER,
                        help='extra run_script.py arguments until the end of the line')
    parser.add_argument('-m', '--match', action='append', metavar='regex',
                        help='Line filter: a line (more precisely, workingdir+SPACE+args) must match any of the regular'
                             ' expressions in order for that test case to be run')
    parser.add_argument('-x', '--exclude', action='append', metavar='regex',
                        help='Negative line filter: a line (more precisely, workingdir+SPACE+args) must NOT match any '
                             'of the regular expressions in order for that test case to be run')
    parser.add_argument('--log-file',
                        required=False,
                        dest="log_file",
                        default="crownet_test.out",
                        help="output file for all tests")

    parser.set_defaults(main_func=crownet_main)
    return parser


def parse_arguments(_args=None):
    defaultNumThreads = multiprocessing.cpu_count()
    if defaultNumThreads > 2:
        defaultNumThreads -= 2
    main = argparse.ArgumentParser(
        description="Run the fingerprint tests specified as OMNeT++ or CrowNet fingerprint files."
    )
    # PARENT
    parent = argparse.ArgumentParser(add_help=False)
    parent.add_argument('-C', '--directory',
                        help='Change to DIRECTORY before executing the tests. Working dirs in the test files are relative to this.', 
                        default=os.getcwd())
    parent.add_argument('-t', '--threads', type=int, default=defaultNumThreads,
                        help='number of parallel threads (default: number of CPUs, currently ' + str(
                            defaultNumThreads) + ')')
    parent.add_argument("--output-dir", default="results", dest="output_dir",
                        help="Directory where simulation output is placed")
    parent.add_argument(
        "--verbose",
        "-v",
        dest="verbose",
        action="count",
        default=0,
        help="Set verbosity of command. From warnings and errors only (-v) to debug output (-vvv)",
    )
    parent.add_argument(
        "--create-log-file",
        dest="create_log_file",
        action="store_true",
        default=False,
        required=False,
        help="Redirect log messages to Logfile at script location.",
    )
    parent.add_argument('-r', '--repeat', type=int, default=1, help='number of repeating each test (default: 1)')

    sub = main.add_subparsers(title="Available Commands", dest='subparser_name')

    # COMMAND 1 "opp"
    opp_argparser(sub.add_parser(
        "opp",
        parents=[parent],
        description="Run OMNeT++ fingerprints"
    ))
    # COMMAND 2 "crownet"
    crownet_argparser(sub.add_parser(
        "crownet",
        parents=[parent],
        description="Run CrowNet fingerprints"
    ))

    parsed_args = main.parse_args(_args)

    if not parsed_args.subparser_name:
        main.error("Please specify one of the subcommands \"opp\" or \"crownet\".")

    return parsed_args


if __name__ == "__main__":

    args = parse_arguments()

    # logger: remove existing handlers and overwrite with user settings
    for h in logging.root.handlers:
        logging.root.removeHandler(h)

    levels = [logging.ERROR, logging.WARN, logging.INFO, logging.DEBUG]
    level_idx = args.verbose
    if args.create_log_file:
        logging.basicConfig(
            level=levels[level_idx],
            format="%(asctime)s:%(module)s:%(levelname)s> %(message)s",
            filename=f"{os.getcwd()}/runner.log",
        )
    else:
        logging.basicConfig(
            level=levels[level_idx],
            format="%(asctime)s:%(module)s:%(levelname)s> %(message)s",
        )

    # roveranalyzer logging
    level_idx = args.verbose
    set_level(levels[level_idx])
    set_format("%(asctime)s:%(module)s:%(levelname)s> %(message)s")

    # FIXME refactor global object
    # Set global object
    TestGlobal.logFile = args.log_file
    if os.path.isfile(TestGlobal.logFile):
        FILE = open(TestGlobal.logFile, "w")
        FILE.close()

    if args.executable:
        TestGlobal.executable = args.executable

    if args.directory:
        TestGlobal.rootDir = os.path.abspath(args.directory)

    if args.extra_args:
        for _arg_list in args.extra_args:
            for _arg in _arg_list:
                TestGlobal.extraArgs += " " + _arg

    # call command main
    TestGlobal.container_names.clear()
    ret = args.main_func(args)

    stop_containers(TestGlobal.container_names)

    if ret == 0:
        print("Test results equals to expected results")
    else:
        print(f"Test results differ from expected results {ret}")
    exit(ret)
